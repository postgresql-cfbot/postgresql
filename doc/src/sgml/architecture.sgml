<!-- doc/src/sgml/architecture.sgml -->

 <chapter id="tutorial-architecture">
  <title>Overview of Architecture and Implementation</title>

  <para>
   Every DBMS implements basic strategies to ensure a fast
   and robust system. This chapter provides an overview of the
   basic techniques <productname>PostgreSQL</productname> uses to
   achieve this aim. It does not offer anything which exceeds
   the information content of other pages. Instead, it tries to
   explain <emphasis>why</emphasis> certain implementation
   decisions have been taken.
  </para>

  <sect1 id="tutorial-ram-proc-file">
   <title>Collaboration of Processes, RAM, and Files</title>
   <para>
    In a client/server architecture clients do not have direct access
    to database files and the data stored in them. Instead, they send
    requests to the server and receive the requested data in the response.
    In the case of <productname>PostgreSQL</productname>, the server
    launches a single process for each client connection, referred to as a
    <glossterm linkend="glossary-backend">Backend</glossterm> process.
    Such a Backend process handles the client's requests by acting on the
    <glossterm linkend="glossary-shared-memory">Shared Memory</glossterm>.
    This leads to other activities (file access, WAL, vacuum, ...) of the
    <glossterm linkend="glossary-instance">Instance</glossterm>. The
    Instance is a group of server-side processes acting on a common
    Shared Memory. PostgreSQL does not use threading.
   </para>

   <para>
    All aspects of an Instance are launched and managed using a single primary
    process termed the
    <glossterm linkend="glossary-postmaster">Postmaster</glossterm>.
    It loads configuration files, allocates Shared Memory, and
    starts the other collaborating processes of the Instance:
    <glossterm linkend="glossary-background-writer">Background Writer</glossterm>,
    <glossterm linkend="glossary-checkpointer">Checkpointer</glossterm>,
    <glossterm linkend="glossary-wal-writer">WAL Writer</glossterm>,
    <glossterm linkend="glossary-wal-archiver">WAL Archiver</glossterm>,
    <glossterm linkend="glossary-autovacuum">Autovacuum</glossterm>,
    <glossterm linkend="glossary-stats-collector">Statistics Collector</glossterm>,
    <glossterm linkend="glossary-logger">Logger</glossterm>, and more.
    Later, the Postmaster listens on its configured system port and in response
    to client connection attempts launches
    <glossterm linkend="glossary-backend">Backend</glossterm> processes
    to which it delegates authentication, communication, and the handling of their requests.
    <xref linkend="tutorial-ram-proc-file-figure"/> visualizes the processes
    of an Instance and the main aspects of their collaboration.
   </para>

   <figure id="tutorial-ram-proc-file-figure">
    <title>Architecture</title>
    <mediaobject>
     <imageobject role="html">
      <!-- distinction html/pdf is necessary to keep font-size of SVG text
           in correlation with font-size of surrounding HTML -->
      <imagedata fileref="images/ram-proc-file-raw.svg" format="SVG" />
     </imageobject>
     <imageobject role="fo">
      <!-- For PDF attribute 'width=100%' is necessary to keep complete SVG visible
           on the page, which has a fixed width. Font sizes will be adopted.  -->
      <imagedata fileref="images/ram-proc-file-raw.svg" format="SVG" width="100%" />
     </imageobject>
    </mediaobject>
   </figure>

   <para>
    Client requests like <command>SELECT</command> or
    <command>UPDATE</command> usually lead to the
    necessity to read or write data. This is carried out
    by the client's backend process. Reads involve a page-level
    cache, located in Shared Memory (for details see:
    <xref linkend="sysvipc"/>) for the benefit of all processes
    in the Instance. Writes also use this cache, in addition
    to a journal, called the write-ahead-log or WAL.
   </para>

   <para>
    Shared Memory is limited in size and it can become necessary
    to evict pages. As long as the content of such pages hasn't
    changed, this is not a problem. But writes directly modify
    the pages in Shared Memory. Modified pages are called dirty
    pages (or dirty buffers) and before they can be evicted they
    must be written to disk. This happens regularly by the
    Checkpointer and the Background Writer processes to ensure
    that the disk version of the pages are up-to-date.
    The synchronization from RAM to disk consists of two steps.
   </para>

   <para>
    First, whenever the content of a page changes, a
    <glossterm linkend="glossary-wal-record">WAL record</glossterm>
    is created from the delta-information (difference between the
    old and the new content) and stored in another area of
    Shared Memory. The concurrently running WAL Writer process
    reads them and appends them to the end of the current
    <glossterm linkend="glossary-wal-record">WAL file</glossterm>.
    Such sequential writes are faster than writes to random
    positions of heap and index files. All WAL records created
    from one dirty page must be transferred to disk before the
    dirty page itself can be transferred to disk in the second step.
   </para>

   <para>
    Second, the Instance transfers dirty buffers from Shared Memory to
    files. This is the primary task of the
    Background Writer process. Because I/O activities can block
    other processes, it starts periodically and
    acts only for a short period. Doing so, its extensive (and
    expensive) I/O activities are spread over time, avoiding
    debilitating I/O peaks. The Checkpointer process
    also transfers dirty buffers to file.
   </para>

   <para>
    The Checkpointer process creates
    <glossterm linkend="glossary-checkpoint">Checkpoints</glossterm>.
    A Checkpoint is a point in time when all older dirty buffers,
    all older WAL records, and finally a special Checkpoint record
    are written and flushed to disk.
    Older WAL files are no longer required to recover the system from a crash.
   </para>

   <para>
    While the Checkpointer ensures that the database system can,
    after a crash, restart itself in a valid state, the administrator needs
    to handle the case where the heap or other files become
    corrupted (and possibly the locally written WAL, though that is
    less common). Options and details are covered
    in the backup and restore section (<xref linkend="backup"/>).
    For our purposes here, just note that the WAL Archiver process
    can be enabled and configured to run a script on completed WAL
    files &mdash; usually to copy them to a remote location. Note
    that when a Checkpoint record is written to the WAL the current
    file is immediately completed.
   </para>

   <para>
    The Statistics Collector collects counters about access to
    SQL objects like tables, rows, indexes, pages, and more. It
    stores the obtained information in system tables.
   </para>

   <para>
    The Logger writes text lines about serious and less serious
    events that may happen during database access, e.g., wrong
    password, no permission, long-running queries, etc.
   </para>

  </sect1>

  <sect1 id="tutorial-cluster-db-schema">
   <title>The logical Perspective: Cluster, Database, Schema</title>

   <para>
    A <glossterm linkend="glossary-server">Server</glossterm> contains one or more
    <glossterm linkend="glossary-db-cluster">Database Clusters</glossterm>
    (<glossterm linkend="glossary-db-cluster">Clusters</glossterm>
    for short). By default each newly initialized Cluster contains three
    <glossterm linkend="glossary-database">databases</glossterm>
    (one interactive and two templates, see <xref linkend="app-initdb"/>).
    Each database can contain many user-writable
    <glossterm linkend="glossary-schema">schemas</glossterm>
    (public, by name and permissiveness, by default), the system
    generated user-facing schemas <literal>pg_catalog</literal>,
    <literal>pg_temp</literal>, and <literal>information_schema</literal>,
    and some more system schemas.
    <glossterm linkend="glossary-table">Tables</glossterm>,
    <glossterm linkend="glossary-view">views</glossterm>, and a lot
    of other objects uniquely reside in a single schema.
    <xref linkend="tutorial-cluster-db-schema-figure"/> visualizes
    this hierarchy.
   </para>

   <para>
    <!-- is the para helpful at this position? -->
    Client connections act at the database level and can access
    its schemas simultaneously. Special techniques like
    <link linkend="sql-createforeigndatawrapper">foreing data wrapper</link>
    or <link linkend="dblink">dblink</link> are required
    to access multiple databases, even within the same Cluster,
    from a single client connection.
   </para>

   <figure id="tutorial-cluster-db-schema-figure">
    <title>Cluster, Database, Schema</title>
    <mediaobject>
     <imageobject role="html">
      <!-- distinction html/pdf is necessary to keep font-size of SVG text
           in correlation with font-size of surrounding HTML -->
      <imagedata fileref="images/cluster-db-schema-raw.svg" format="SVG" />
     </imageobject>
     <imageobject role="fo">
      <!-- For PDF attribute 'width=100%' is necessary to keep complete SVG visible
           on the page, which has a fixed width. Font sizes will be adopted.  -->
      <imagedata fileref="images/cluster-db-schema-raw.svg" format="SVG" width="100%" />
     </imageobject>
    </mediaobject>
   </figure>

   <para>
    A Cluster is the outer container for a
    collection of databases. Clusters are created by the command
    <xref linkend="app-initdb"/>.
   </para>

   <para>
    <literal>template0</literal> is the very first
    database of any Cluster. It
    is created during the initialization phase of the Cluster.
    In a second step, database <literal>template1</literal> is generated
    as a copy of <literal>template0</literal>, and finally database
    <literal>postgres</literal> is generated as a copy of
    <literal>template1</literal>. Any
    <glossterm linkend="app-createdb">new databases</glossterm>
    of the Cluster that a user might need,
    such as <literal>my_db</literal>, will be copied from the
    <literal>template1</literal> database. Due to the unique
    role of <literal>template0</literal> as the pristine original
    of all other databases, no client is allowed to connect to it.
   </para>

   <para>
    <glossterm linkend="glossary-sql-object">SQL Objects</glossterm>
    are contained in a schema.
    Schemas are namespaces for SQL objects and ensure
    (with one exception) that the SQL object names are used only once within
    their scope across all types of SQL objects. E.g., it is not possible
    to have a table <literal>employee</literal> and a view
    <literal>employee</literal> within the same schema. But it is
    possible to have two tables <literal>employee</literal> in two
    different schemas. In this case, the two tables
    are separate objects and independent of each
    other. The only exception to this cross-type uniqueness is that
    <glossterm linkend="glossary-unique-constraint">unique constraints
    </glossterm> and the according unique index
    (<xref linkend="indexes-unique"/>) use the same name.
   </para>

   <para>
    Some schemas are predefined. <literal>public</literal>
    acts as the default schema and contains all SQL objects
    which are created within <literal>public</literal> or
    without using an explicit schema name. <literal>public</literal>
    should not contain user-defined SQL objects. Instead, it is
    recommended to create a separate schema that holds individual
    objects like application-specific tables or views. To access
    objects in such a schema they can be fully qualified, e.g.
    <literal>my_schema.my_table</literal>, or by changing the
    <link linkend="ddl-schemas-path">schema search path</link>.
   </para>

   <para>
    <literal>pg_catalog</literal> is a schema for all tables and views of the
    <glossterm linkend="glossary-system-catalog">System Catalog</glossterm>.
    <literal>information_schema</literal> is a similar schema. It
    contains several tables and views of the System Catalog in a
    way that conforms to the SQL standard.
   </para>

   <para>
    There are many different SQL object types:
    <glossterm linkend="glossary-database">database</glossterm>,
    <glossterm linkend="glossary-schema">schema</glossterm>,
    <glossterm linkend="glossary-table">table</glossterm>,
    <glossterm linkend="glossary-view">view</glossterm>,
    <glossterm linkend="glossary-materialized-view">materialized view</glossterm>,
    <glossterm linkend="glossary-index">index</glossterm>,
    <glossterm linkend="glossary-constraint">constraint</glossterm>,
    <glossterm linkend="glossary-sequence">sequence</glossterm>,
    <glossterm linkend="glossary-function">function</glossterm>,
    <glossterm linkend="glossary-procedure">procedure</glossterm>,
    <glossterm linkend="glossary-trigger">trigger</glossterm>,
    <glossterm linkend="glossary-role">role</glossterm>,
    <glossterm linkend="datatype">data type</glossterm>,
    <glossterm linkend="functions">operator</glossterm>,
    <glossterm linkend="glossary-tablespace">tablespace</glossterm>,
    <glossterm linkend="glossary-extension">extension</glossterm>,
    <glossterm linkend="glossary-foreign-data-wrapper">foreign data wrapper</glossterm>,
    and more. A few of them, the
    <firstterm>Global SQL Objects</firstterm>, are outside of the
    strict hierarchy: All <firstterm>database names</firstterm>,
    all <firstterm>tablespace names</firstterm>, and all
    <firstterm>role names</firstterm> are automatically
    available throughout the Cluster, not just the database in which
    the SQL command was executed.
    <xref linkend="tutorial-internal-objects-hierarchy-figure"/>
    shows the relation between the object types.
   </para>

   <figure id="tutorial-internal-objects-hierarchy-figure">
    <title>Hierarchy of Internal Objects</title>
    <mediaobject>
     <imageobject role="html">
      <!-- distinction html/pdf is necessary to keep font-size of SVG text
           in correlation with font-size of surrounding HTML -->
      <imagedata fileref="images/internal-objects-hierarchy-raw.svg" format="SVG" />
     </imageobject>
     <imageobject role="fo">
      <!-- For PDF attribute 'width=100%' is necessary to keep complete SVG visible
           on the page, which has a fixed width. Font sizes will be adopted.  -->
      <imagedata fileref="images/internal-objects-hierarchy-raw.svg" format="SVG" width="100%" />
     </imageobject>
    </mediaobject>
   </figure>

  </sect1>

  <sect1 id="tutorial-directories">
   <title>The Physical Perspective: Directories and Files</title>

   <para>
    <productname>PostgreSQL</productname> organizes long-lasting (persistent)
    data as well as volatile state information about transactions
    or replication actions in the file system. Every
    <xref linkend="glossary-db-cluster"/> has its root directory
    somewhere in the file system. In many cases, the environment
    variable <literal>PGDATA</literal> points to this directory.
    The example shown in
    <xref linkend="tutorial-directories-figure"/> uses
    <literal>data</literal> as the name of the cluster's root directory.
   </para>

   <figure id="tutorial-directories-figure">
    <title>Directory Structure</title>
    <mediaobject>
     <imageobject role="html">
      <!-- distinction html/pdf is necessary to keep font-size of SVG text
           in correlation with font-size of surrounding HTML -->
      <imagedata fileref="images/directories-raw.svg" format="SVG" />
     </imageobject>
     <imageobject role="fo">
      <!-- For PDF attribute 'width=100%' is necessary to keep complete SVG visible
           on the page, which has a fixed width. Font sizes will be adopted.  -->
      <imagedata fileref="images/directories-raw.svg" format="SVG" width="100%" />
     </imageobject>
    </mediaobject>
   </figure>

   <para>
    The cluster's root directory contains many subdirectories and
    some files, all of which are necessary to store long-lasting
    as well as temporary data. The root's name can be selected
    as desired, but the names of its subdirectories and files
    are more or less fix and detertermined by
    <productname>PostgreSQL</productname>. The following
    paragraphs describe the most important subdirectories
    and files.
   </para>

   <para>
    <literal>base</literal> contains one
    subdirectory per database. The names of those
    subdirectories consist of numbers. These are the internal
    Object Identifiers (OID), which are numbers to identify
    their definition in the
    <glossterm linkend="glossary-system-catalog">System Catalog</glossterm>.
   </para>

   <para>
    Within the database-specific subdirectories of <literal>base</literal>
    there are many files: one or more for every table
    and every index. Those files are accompanied by files for the
    <link linkend="storage-fsm">Free Space Maps</link>
    (suffixed <literal>_fsm</literal>) and
    <link linkend="storage-vm">Visibility Maps</link>
    (suffixed <literal>_vm</literal>), which contain optimization information.
   </para>

   <para>
    Another subdirectory is <literal>global</literal>. It
    contains files with information about
    <glossterm linkend="glossary-sql-object">Global SQL Objects</glossterm>.
   </para>

   <para>
    In <literal>pg_tblspc</literal>, there are symbolic links
    that point to directories that are outside of the root
    directory tree, e.g. at a different disc. Files for tables
    and indexes of non-default tablespaces reside there. As
    previously mentioned, those defined within the default
    tablespace reside in the database-specific subdirectories.
   </para>

   <para>
    The subdirectory <literal>pg_wal</literal> contains the
    <glossterm linkend="glossary-wal-file">WAL files</glossterm>.
    They arise and grow in parallel with data changes in the
    Cluster and remain as long as
    they are required for recovery, archiving, or replication.
   </para>

   <para>
    The subdirectory <literal>pg_xact</literal> contains
    information about the status of each transaction:
    <literal>in_progress</literal>, <literal>committed</literal>,
    <literal>aborted</literal>, or <literal>sub_committed</literal>.
   </para>

   <para>
    In the root directory
    there are also some files. In many cases, the configuration
    files of the Cluster are stored here. If the
    Instance is up and running, the file
    <literal>postmaster.pid</literal> exists here
    (by default)
    and contains the process ID (pid) of the
    Postmaster which started the Instance.
   </para>

   <para>
    For more details about the physical implementation
    of database objects, see <xref linkend="storage"/>.
   </para>

  </sect1>

  <sect1 id="tutorial-mvcc">
   <title>MVCC &mdash; Multiversion Concurrency Control</title>

   <para>
    In most cases, <productname>PostgreSQL</productname> databases
    support many clients at the same time which makes it necessary to
    protect concurrently running requests from unwanted overwriting
    of other's data as well as from reading inconsistent data. Imagine an
    online shop offering the last copy of an article. Two clients have the
    article displayed at their user interface. After a while, but at the same time,
    both users decide to put it to their shopping cart or even to buy it.
    Both have seen the article, but only one can be allowed to get it.
    The database must bring the two requests in a row, permit the access
    to one of them, block the other, and inform the blocked client
    that the data was changed by a different process.
   </para>

   <para>
    <productname>PostgreSQL</productname> implements a
    sophisticated technique which avoids locking:
    <firstterm>Multiversion Concurrency Control</firstterm> (MVCC).
    The advantage of MVCC over technologies that use row locks
    becomes evident in multiuser Online Transaction Processing (OLTP)
    environments with a massive number of concurrent write
    actions. There, MVCC generally performs better than solutions
    using locks. In a <productname>PostgreSQL</productname>
    database, reading never blocks writing and writing never
    blocks reading, even in the strictest level of transaction
    isolation.
   </para>

   <para>
    Instead of locking rows, the <firstterm>MVCC</firstterm> technique creates
    a new version of the row when a data-change takes place. To
    distinguish between these two versions, and to track the timeline
    of the row, each of the versions contains, in addition to their user-defined
    columns, two special system columns, which are not visible
    for the usual <command>SELECT * FROM ...</command> command.
    The column <literal>xmin</literal> contains the transaction ID (xid)
    of the transaction which created this version of the row.
    <literal>xmax</literal> contains the xid of the transaction which has
    deleted this version, or zero if the version is not
    deleted. You can read both with the command
    <command>SELECT xmin, xmax, * FROM ... </command>.
   </para>

   <para>
    Xids are sequences (with a reserved value to handle wrap-around
    in pre-9.4 <productname>PostgreSQL</productname> versions).
    Age computations involving them measure a transaction
    count as opposed to a time interval (in milliseconds or otherwise).
    If you dive deeper into <productname>PostgreSQL</productname>,
    you will recognize parameters with names such as 'xxx_age'.
    Despite their names, these '_age' parameters do not specify
    a period of time but represent a certain number of transactions,
    e.g., 100 million.
   </para>

   <para>
    The description in this chapter simplifies by omitting details.
    When many transactions are running simultaneously, things can
    get complicated. Sometimes transactions are aborted via
    <command>ROLLBACK</command> immediately or after a lot of other activities, sometimes
    a single row is involved in more than one transaction, sometimes
    a client crashes, sometimes the sequence of xids restarts
    from zero, ... . Therefore, every version of a row contains more
    system columns and flags, not only <literal>xmin</literal>
    and <literal>xmax</literal>.
   </para>

   <para>
    So, what's going on in detail when write access takes place?
    <xref linkend="tutorial-mvcc-figure"/> shows details concerning
    <literal>xmin</literal>, <literal>xmax</literal>, and user data.
   </para>

   <figure id="tutorial-mvcc-figure">
    <title>Multiversion Concurrency Control</title>
    <mediaobject>
     <imageobject role="html">
      <!-- distinction html/pdf is necessary to keep font-size of SVG text
           in correlation with font-size of surrounding HTML -->
      <imagedata fileref="images/mvcc-raw.svg" format="SVG" />
     </imageobject>
     <imageobject role="fo">
      <imagedata fileref="images/mvcc-raw.svg" format="SVG" width="100%" />
     </imageobject>
    </mediaobject>
   </figure>

   <para>
    An <command>INSERT</command> command creates the first
    version of a row. Besides its user data <literal>'x'</literal>,
    this version contains the ID of the creating transaction
    <literal>123</literal> in <literal>xmin</literal> and
    <literal>0</literal> in <literal>xmax</literal>.
    <literal>xmin</literal> indicates that the version
    exists since transaction <literal>123</literal> and
    <literal>xmax</literal> that it is currently not deleted.
   </para>

   <para>
    Somewhat later, transaction <literal>135</literal>
    executes an <command>UPDATE</command> of this row by
    changing the user data from <literal>'x'</literal> to
    <literal>'y'</literal>. According to the MVCC principles,
    the data in the old version of the row is not changed.
    The value <literal>'x'</literal> remains as it was before.
    Only <literal>xmax</literal> changes to <literal>135</literal>.
    Now, this version is treated as valid exclusively for
    transactions with xids from <literal>123</literal> to
    <literal>134</literal>. In addition to the non-occurring
    data change in the old version, the <command>UPDATE</command>
    creates a new version of the row with its xid in
    <literal>xmin</literal>, <literal>0</literal> in
    <literal>xmax</literal>, and <literal>'y'</literal> in the
    user data (plus all other user data from the old version).
    This new row version is visible to all future transactions.
    (Internally, an <command>UPDATE</command> command acts
    as a <command>DELETE</command> command followed by
    an <command>INSERT</command> command.)
   </para>

   <para>
    All subsequent <command>UPDATE</command> commands behave
    in the same way as the first one: they put their xid in
    <literal>xmax</literal> of the current version, create
    a new version with their xid in <literal>xmin</literal> and
    <literal>0</literal> in <literal>xmax</literal>.
   </para>

   <para>
    Finally, a row may be deleted by a <command>DELETE</command>
    command. Even in this case, all versions of the row remain as
    before; nothing is thrown away. Only <literal>xmax</literal>
    of the last version is set to the xid of the <command>DELETE</command>
    transaction, which indicates that (if committed) it is only visible to
    transactions with xids older than that (from
    <literal>142</literal> to <literal>820</literal> in this
    example).
   </para>

   <para>
    In summary, the MVCC technology creates more and more versions
    of the same row in the table's heap file and leaves them there,
    even after a <command>DELETE</command> command. Only the youngest
    version is relevant for all future transactions. But the
    system must also preserve some of the older ones for
    awhile, because they could still be needed by
    transactions which started before the deleting transaction commits.
    Over time, also the older ones get out of scope
    for ALL transactions and therefore become unnecessary.
    Nevertheless, they do exist physically on the disk and occupy
    space. They are called <firstterm>dead rows</firstterm> and are part
    of the <glossterm linkend="glossary-bloat">bloat</glossterm>.
   </para>

   <para>
    Keep in mind:
   </para>
   <itemizedlist>

    <listitem>
     <simpara>
      <literal>xmin</literal> and <literal>xmax</literal>
      indicate the range in which
      <firstterm>row versions</firstterm> are valid (visible) for transactions.
      This range doesn't imply any direct temporal meaning;
      the sequence of xids reflects only the sequence of
      transaction begin events.
     </simpara>
    </listitem>

    <listitem>
     <simpara>
      Internally, an <command>UPDATE</command> command acts in the
      same way as a <command>DELETE</command> command followed by
      an <command>INSERT</command> command.
     </simpara>
    </listitem>

    <listitem>
     <simpara>
      Nothing is removed &mdash; with the consequence that the database
      occupies more and more disk space. It is obvious that
      this behavior has to be corrected in some way. The next
      chapter explains how <firstterm>vacuum</firstterm> and
      <firstterm>autovacuum</firstterm> fulfill this task.
     </simpara>
    </listitem>

   </itemizedlist>

  </sect1>

  <sect1 id="tutorial-vacuum">
   <title>Vacuum</title>

   <para>
    As we have seen in the previous chapter, the database
    tends to occupy more and more disk space, caused by
    <glossterm linkend="glossary-bloat">bloat</glossterm>.
    This chapter explains how the SQL command
    <command>VACUUM</command> and the automatically running
    <firstterm>Autovacuum</firstterm> processes clean up
    and prevent continued growth.
   </para>

   <note>
    <para>
     Autovacuum runs automatically, by
     default. Its default parameters as well as those for
     <command>VACUUM</command> are appropriate for most standard
     situations. Therefore a novice database manager can
     skip the rest of this chapter which explains
     a lot of details.
    </para>
   </note>

   <para>
    Client processes can issue the SQL command <command>VACUUM</command>
    at any time. DBAs do this when they recognize
    special situations, or they start it in batch jobs which run
    periodically. Additionally, there is a constantly running
    Autovacuum daemon which is part of the
    <link linkend="glossary-instance">Instance</link>. It continuously
    monitors the state of all databases based on values that are collected by the
    <link linkend="glossary-stats-collector">Statistics Collector</link>
    and starts Autovacuum processes whenever it detects
    certain situations. Thus, it's a dynamic behavior of
    <productname>PostgreSQL</productname> with the intention to tidy
    up whenever it is appropriate.
   </para>

   <para>
    <command>VACUUM</command>, as well as Autovacuum, don't just eliminate
    bloat. They perform additional tasks for minimizing future
    I/O activities of themselves as well as of other processes.
    This extra work can be done in a very efficient way since in most
    cases the expensive physical access to pages has taken place anyway
    to eliminate bloat. The additional operations are:
   </para>

   <itemizedlist>

    <listitem>
     <simpara>
      <firstterm>Freeze</firstterm>: Mark certain row versions
      as frozen. This means that they
      are always treated as valid (visible) independent from
      the <firstterm>wraparound problem</firstterm> (see below).
     </simpara>
    </listitem>

    <listitem>
     <simpara>
      <firstterm>Visibility Map</firstterm> and
      <firstterm>Free Space Map</firstterm>: Log information about
      the state of the handled pages in two additional files, the
      Visibility Map and the Free Space Map.
     </simpara>
    </listitem>

    <listitem>
     <simpara>
      <emphasis>Statistics</emphasis>: Collect statistics about the
      number of rows per table, the distribution of values, and so on,
      as the basis for decisions of the query planner.
     </simpara>
    </listitem>

   </itemizedlist>

   <para>
    The eagerness &mdash; or 'aggressiveness' &mdash; of the
    operations for <emphasis>eliminating bloat</emphasis> and
    <emphasis>freeze</emphasis> is controlled by configuration
    parameters, runtime flags, and in extreme situations by
    the processes themselves. Because vacuum operations typically are I/O
    intensive, which can hinder other activities, Autovacuum
    avoids performing many vacuum operations in bulk. Instead,
    it carries out many small actions with delay points in between.
    The SQL command <command>VACUUM</command> runs immediately
    and without any time delay.
   </para>

   <bridgehead renderas="sect2">Eliminate Bloat</bridgehead>

   <para>
    To determine which of the row versions are no longer needed, the
    elimination operation must evaluate <literal>xmax</literal>
    against several criteria which must all apply:
   </para>
   <itemizedlist>

    <listitem>
     <simpara>
      <literal>xmax</literal> must be different from zero because a
      value of zero indicates that the row version is still valid.
     </simpara>
    </listitem>

    <listitem>
     <simpara>
      <literal>xmax</literal> must contain an xid which is older
      than the oldest xid of all currently running transactions
      <literal>(min(pg_stat_activity.backend_xmin))</literal>.
      This criterion guarantees that no existing or upcoming transaction
      will have read or write access to this row version.
     </simpara>
    </listitem>

    <listitem>
     <simpara>
      The transaction of <literal>xmax</literal> must be committed. If it was rollback-ed,
      this row version is treated as valid.
     </simpara>
    </listitem>

    <listitem>
     <simpara>
      If there is the situation that the row version is part of
      multiple transactions, special care and some more actions
      must be taken, see: <xref linkend="vacuum-for-multixact-wraparound"/>.
     </simpara>
    </listitem>

   </itemizedlist>

   <para>
    After the vacuum operation detects an unused row version, it
    marks its space as free for future use of writing actions. Only
    in rare situations (or in the case of <command>VACUUM FULL</command>),
    is this space released to the operating system. In most cases,
    it remains occupied by <productname>PostgreSQL</productname>
    and will be used by future <command>INSERT</command> or
    <command>UPDATE</command> commands to this table.
   </para>

   <para>
    Which actions start the elimination of bloat?

    <itemizedlist>

     <listitem>
      <simpara>
       When a client issues the SQL command <command>VACUUM</command>
       in its default format, i.e., without any option. To boost performance,
       in this and the next case <command>VACUUM</command> does not
       read and act on all pages of the heap file.
       The Visibility Map, which is very compact and therefore fast to read,
       contains information about which pages have no deleted row versions, and
       can be skipped by <command>VACUUM</command>.
      </simpara>
     </listitem>

     <listitem>
      <simpara>
       When a client issues the SQL command <command>VACUUM</command>
       with the option <command>FREEZE</command>. (In this case,
       it undertakes many more actions, see
       <link linkend="tutorial-freeze">Freeze Row Versions</link>.)
      </simpara>
     </listitem>

     <listitem>
      <simpara>
       When a client issues the SQL command <command>VACUUM</command>
       with the option <command>FULL</command>.
       In this mode, an exclusive lock is taken, and
       the whole table is copied to a different file, skipping all outdated row
       versions.  All bloat is thereby eliminated, which
       may lead to a significant reduction of used disk space.
       The old file is deleted.
      </simpara>
     </listitem>

     <listitem>
      <simpara>
       When an Autovacuum process acts. For optimization
       purposes, it considers the Visibility Map in the same way as
       <command>VACUUM</command>. Additionally, it ignores tables with few modifications;
       see <xref linkend="guc-autovacuum-vacuum-threshold"/>,
       which defaults to 50 rows and
       <xref linkend="guc-autovacuum-vacuum-scale-factor"/>,
       which defaults to 20%.
      </simpara>
     </listitem>

    </itemizedlist>
   </para>

   <para>
    This logic only applies to row versions of the heap. Index entries
    don't use <literal>xmin/xmax</literal>. Nevertheless, such index
    entries, which would lead to outdated row versions, are cleaned up
    accordingly.
   </para>

   <para>
    The above descriptions omit the fact that xids on a real computer
    have a limited size, and after
    a certain number of transactions they are forced to restart
    from the beginning, which is called <firstterm>wraparound</firstterm>.
    Therefore the terms 'old transaction' / 'young transaction' does
    not always correlate with low / high values of xids. Near to
    wraparound point, there are cases where <literal>xmin</literal> has
    a higher value than <literal>xmax</literal>, although their meaning
    is said to be older than <literal>xmax</literal>.
   </para>

   <figure id="tutorial-wraparound-figure">
    <title>Cyclic usage of XIDs</title>
    <mediaobject>
     <imageobject role="html">
      <!-- distinction html/pdf is necessary to keep font-size of SVG text
           in correlation with font-size of surrounding HTML -->
      <imagedata fileref="images/wraparound-raw.svg" format="SVG" />
     </imageobject>
     <imageobject role="fo">
      <!-- For PDF attribute 'width=100%' is necessary to keep complete SVG visible
           on the page, which has a fixed width. Font sizes will be adopted.  -->
      <imagedata fileref="images/wraparound-raw.svg" format="SVG" width="100%" />
     </imageobject>
    </mediaobject>
   </figure>

   <bridgehead renderas="sect2" id="tutorial-freeze">Freeze Row Versions</bridgehead>

   <para>
    The use of a limited range of IDs for transactions leads
    to the necessity to restart the sequence sooner or later.
    This not only has the rare consequence, previously
    described, that sometimes <literal>xmin</literal> is
    higher than <literal>xmax</literal>. A far
    more critical problem is that whenever the system has
    to evaluate a WHERE condition, it must decide which row
    version is valid (visible) from the perspective of the
    transaction of the query. If a wraparound couldn't happen,
    this decision would be relatively easy: the xid
    must be between <literal>xmin</literal> and <literal>xmax</literal>,
    and the corresponding transactions of <literal>xmin</literal>
    and <literal>xmax</literal> must be committed. However,
    <productname>PostgreSQL</productname> has to consider the
    possibility of wraparound.
    Therefore the decision becomes more complex. The general
    idea of the solution is to use the 'between
    <literal>xmin</literal> and <literal>xmax</literal>'
    comparison only during the youngest period of the row
    versions lifetime and afterward replace it with a
   'valid forever' flag in its header.
   </para>

   <itemizedlist>

    <listitem>
     <simpara>
      As a first step, <productname>PostgreSQL</productname>
      divides the complete range of
      possible xids into two halves with the two split-points
      'txid_current' and 'txid_current + 2^31'. The half behind
      'txid_current' is considered to represent xids of the
      'past' and the half ahead of 'txid_current' those of the
      'future'. Those of the 'past' are valid (visible) and those
      of the 'future' not.
     </simpara>
    </listitem>

    <listitem>
     <simpara>
      With each newly created transaction the two split-points
      move forward. If 'txid_current + 2^31' reached a
      row version with <literal>xmin</literal> equal to that value, it would
      immediately jump from 'past' to 'future' and would be
      no longer visible!
     </simpara>
    </listitem>

    <listitem>
     <simpara>
      If not handled in some way, data inserted many transactions ago
      would become invisibile. The vacuum operation <firstterm>freeze</firstterm>
      avoids this long before the split-point is reached by setting
      a flag in the header of the row version which avoids
      future comparison of its <literal>xmin/xmax</literal> and indicates
      that the version is valid not only in the 'past'-half
      but also in the 'future'-half, as well as in all coming
      <glossterm linkend="glossary-xid">epochs</glossterm>.
     </simpara>
    </listitem>
   </itemizedlist>

   <para>
    Which row versions can be frozen by the vacuum operation?
    Again, several criteria must be checked, and all must be met.

    <itemizedlist>

     <listitem>
      <simpara>
       <literal>xmax</literal> must be zero because only
       non-deleted rows can be visible 'forever'.
      </simpara>
     </listitem>

     <listitem>
      <simpara>
       <literal>xmin</literal> must be older than all currently
       existing transactions. This guarantees that no existing
       transaction can modify or delete the version.
      </simpara>
     </listitem>

     <listitem>
      <simpara>
       The transactions of <literal>xmin</literal> and
       <literal>xmax</literal> must be committed.
      </simpara>
     </listitem>
    </itemizedlist>
   </para>

   <para>
    At what point in time does the freeze operation take place?

    <itemizedlist>
     <listitem>
      <simpara>
       When a client issues the SQL command <command>VACUUM</command>
       with its <command>FREEZE</command> option. In this case, all
       pages are processed that are marked in the Visibility Map
       as potentially having unfrozen rows.
      </simpara>
     </listitem>
     <listitem>
      <simpara>
       When a client issues the SQL command <command>VACUUM</command> without
       any options but there are xids older than
       <xref linkend="guc-vacuum-freeze-table-age"/>
       (default: 150 million) minus
       <xref linkend="guc-vacuum-freeze-min-age"/>
       (default: 50 million).
       As before, all pages are processed that are
       marked in the Visibility Map to potentially having unfrozen
       rows.
      </simpara>
     </listitem>
     <listitem>
      <simpara>
       When an Autovacuum process runs. Such a process acts in one
       of two modes:
      </simpara>

      <itemizedlist>
       <listitem>
        <simpara>
         In the <emphasis>normal mode</emphasis>, it skips
         pages with row versions that are younger than
         <xref linkend="guc-vacuum-freeze-min-age"/>
         (default: 50 million) and works only on pages where
         all xids are older. The skipping of young xids prevents
         work on such pages, which are likely to be changed
         by one of the future SQL commands.
        </simpara>
       </listitem>
       <listitem>
        <simpara>
         The process switches
         to an <emphasis>aggressive mode</emphasis> if it recognizes
         that for the processed table the oldest xid exceeds
         <xref linkend="guc-autovacuum-freeze-max-age"/>
         (default: 200 million). The value of the oldest unfrozen
         xid is stored per table in <literal>pg_class.relfrozenxid</literal>.
         In this <emphasis>aggressive mode</emphasis> Autovacuum
         processes all such pages of the selected table that are marked
         in the Visibility Map to potentially have bloat or unfrozen rows.
        </simpara>
       </listitem>

      </itemizedlist>
     </listitem>
    </itemizedlist>
   </para>

   <para>
    In the first two cases and with Autovacuum in
    <emphasis>aggressive mode</emphasis>, the system knows
    to which value the oldest unfrozen xid has moved forward and
    logs the value in <literal>pg_class.relfrozenxid</literal>.
    The distance between this value and the 'txid_current' split
    point becomes smaller, and the distance to 'txid_current + 2^31'
    becomes larger than before.
   </para>

   <figure id="tutorial-freeze-figure">
    <title>Freeze</title>
    <mediaobject>
     <imageobject role="html">
      <!-- distinction html/pdf is necessary to keep font-size of SVG text
           in correlation with font-size of surrounding HTML -->
      <imagedata fileref="images/freeze-raw.svg" format="SVG" />
     </imageobject>
     <imageobject role="fo">
      <!-- For PDF attribute 'width=100%' is necessary to keep complete SVG visible
           on the page, which has a fixed width. Font sizes will be adopted.  -->
      <imagedata fileref="images/freeze-raw.svg" format="SVG" width="100%" />
     </imageobject>
    </mediaobject>
   </figure>

   <bridgehead renderas="sect2">Protection against Wraparound Failure</bridgehead>

   <para>
    The Autovacuum processes are initiated by the constantly running
    Autovacuum daemon. If the daemon detects that for a table
    <literal>autovacuum_freeze_max_age</literal> is exceeded, it
    starts an Autovacuum process in <emphasis>aggressive mode</emphasis>
    (see above) &mdash; even if Autovacuum is disabled.
   </para>

   <bridgehead renderas="sect2">Visibility Map and Free Space Map</bridgehead>

   <para>
    The <link linkend="glossary-vm">Visibility Map</link>
    (VM) contains two flags &mdash; stored as
    two bits &mdash; for each page of the heap file. The
    first bit indicates that the associated page does
    not contain any bloat. The second bit indicates
    that the page contains only frozen row versions.
   </para>

   <para>
     Please consider two details. First, in most cases a page
     contains many rows or row versions.
     However, the flags are associated with the page,
     not with an individual row version. The flags are set
     only under the condition that they are valid for ALL
     row versions of the page. Second, since there
     are only two bits per page, the VM is considerably
     smaller than the heap.
   </para>

   <para>
    The setting of the flags is silently done by <command>VACUUM</command>
    and Autovacuum during their bloat and freeze operations.
    This is done to speed up future vacuum actions,
    regular access to heap pages, and some access to
    the index. Every data-modifying operation on any row
    version of the page clears the flags.
   </para>

   <para>
    The <link linkend="glossary-fsm">Free Space Map</link>
    (FSM) tracks the amount of free space per page. It is
    organized as a highly condensed b-tree of (rounded) sizes.
    Whenever <command>VACUUM</command> or Autovacuum changes
    the free space on any processed page, they log the new
    values in the FSM in the same way as all other writing
    processes.
   </para>

   <bridgehead renderas="sect2">Statistics</bridgehead>

   <para>
    Statistical information helps the <link
    linkend="planner-stats">Query Planner</link> to make optimal
    decisions for the generation of execution plans. This
    information can be gathered with the SQL commands
    <command>ANALYZE</command> or <command>VACUUM ANALYZE</command>.
    But Autovacuum processes also gather
    such information. Depending on the percentage of changed rows
    <xref linkend="guc-autovacuum-analyze-scale-factor"/>,
    and minimum number of changed rows <xref linkend="guc-autovacuum-analyze-threshold"/>,
    the Autovacuum daemon starts Autovacuum processes to collect
    statistics per table. The automatic analysis
    allows <productname>PostgreSQL</productname> to
    adapt query execution to changing circumstances.
   </para>

   <para>
    For more details about vacuum operations, especially for its
    numerous parameters, see <xref linkend="routine-vacuuming"/>.
   </para>

  </sect1>

  <sect1 id="tutorial-transactions-mvcc">
   <title>Transactions</title>
   <para>
    <link linkend="tutorial-transactions">Transactions</link>
    are a fundamental concept of relational database systems.
    Their essential point is that they bundle multiple
    read- or write-operations into a single all-or-nothing
    operation. Furthermore, they separate and protect concurrent
    actions of different connections from each other. Thereby
    they implement the ACID paradigm.
   </para>

   <para>
    In <productname>PostgreSQL</productname> there are two ways
    to establish a transaction. The explicit way uses the keywords
    <link linkend="sql-begin">BEGIN</link> and
    <link linkend="sql-commit">COMMIT</link> (respectively
    <link linkend="sql-rollback">ROLLBACK</link>) before
    and after a sequence of SQL statements. The keywords mark
    the transaction's start- and end-point. On the other hand, you
    can omit the keywords. This is the implicit way, where
    every single SQL command automatically establishes a new
    transaction.

    <programlisting>
BEGIN; -- establish a new transaction
UPDATE accounts SET balance = balance - 100.00 WHERE name = 'Alice';
UPDATE accounts SET balance = balance + 100.00 WHERE name = 'Bob';
COMMIT; -- finish the transaction

-- this UPDATE runs as the only command of a separate transaction ...
UPDATE accounts SET balance = balance - 100.00 WHERE name = 'Alice';

-- ... and this one runs in another transaction
UPDATE accounts SET balance = balance + 100.00 WHERE name = 'Bob';
    </programlisting>
   </para>

   <para>
    As mentioned, the primary property of a transaction is its
    atomicity: either all or none of its operations succeed,
    regardless of the fact that it may consist of a lot of
    different write-operations, and each such operation may
    affect many rows. As soon as one of the
    operations fails, all previous operations fail also, which
    means that all modified rows retain their values as of the
    beginning of the transaction.
   </para>

   <para>
    The atomicity also affects the visibility of changes. No
    connection running simultaneously with a data modifying
    transaction will ever see any change before the
    transaction successfully executes a <command>COMMIT</command>
    &mdash; even in the lowest
    <link linkend="transaction-iso">isolation level</link>
    of transactions. <productname>PostgreSQL</productname>
    never shows uncommitted changes to other connections.
   </para>

   <para>
    The situation regarding visibility is somewhat different
    from the point of view of the modifying transaction.
    A <command>SELECT</command> command issued inside a
    transaction shows all changes done so far by this
    transaction.
   </para>

   <bridgehead renderas="sect2">How does it work?</bridgehead>

   <para>
    Every <command>INSERT</command>, <command>UPDATE</command>,
    and <command>DELETE</command> command creates new row
    versions &mdash; according to the MVCC rules. This
    creates the risk that other transactions may see the
    new row versions, and after a while and some more
    activities of the modifying transaction they may see the
    next row versions. Results would be a kind of 'moving
    target' which would be contrary to the all-or-nothing
    principle.
   </para>

   <para>
    <productname>PostgreSQL</productname> overcomes this
    problem by showing only such row versions to other
    transactions whose originating transaction has
    successfully committed. It skips all row versions of
    uncommitted transactions. And
    <productname>PostgreSQL</productname> solves one more
    problem. Even the single <command>COMMIT</command>
    command needs a short time interval for its execution.
    Therefore its critical 'dead-or-survival' phase
    runs in a privileged mode that cannot be
    interrupted by other processes.
   </para>

   <bridgehead renderas="sect2">What are the benefits?</bridgehead>

   <para>
    Transactions relieve applications from many standard
    actions that would otherwise need to be implemented for nearly every use case.
   </para>

   <para>
    Business logic often contains strong, but for a computer,
    relative abstract requirements. The above example shows
    the transfers of some money from one account to another.
    It is obvious
    that the decrease of the one account and the increase of the
    other must be indivisible. Nevertheless, there is no particular
    need for an application to do something to ensure the
    <glossterm linkend="glossary-atomicity">atomicity</glossterm>
    of this behavior. It's enough to surround them with
    <command>BEGIN</command> and <command>COMMIT</command>.
   </para>

   <para>
    Applications often demand the feature of 'undoing'
    previously taken actions under some application-specific
    conditions. In such cases, the application simply issues a
    <command>ROLLBACK</command> command instead of a
    <command>COMMIT</command>. The <command>ROLLBACK</command>
    cancels the transaction, and all changes made so far remain
    invisible forever; it is as if they had never happened. There
    is no need for the application to log its activities and
    undo every step of the transaction separately.
   </para>

   <para>
    Transactions ensure that the
    database always remains
    <glossterm linkend="glossary-consistency">consistent</glossterm>.
    Declarative rules like
    <link linkend="ddl-constraints-primary-keys">primary</link>- or
    <link linkend="ddl-constraints-fk">foreign keys</link>,
    <link linkend="ddl-constraints-check-constraints">checks</link>,
    other constraints, or
    <link linkend="trigger-definition">triggers</link>
    are part of the all-or-nothing nature of transactions.
   </para>

   <para>
    There is the additional feature
    '<link linkend="transaction-iso">isolation level</link>',
    which separates transactions from each other in certain ways.
    It automatically prevents applications from some strange
    situations.
   </para>

   <para>
    Lastly, it is worth noticing that changes done by a
    committed transaction will survive all failures in the application or
    the Database Cluster. The next chapter explains the
    <glossterm linkend="glossary-durability">durability</glossterm>
    guarantees.
   </para>
  </sect1>

  <sect1 id="tutorial-reliability">
   <title>Reliability</title>

   <para>
    Nothing is perfect and failures inevitably happen.
    However, the most common types of failure are
    well known and <productname>PostgreSQL</productname>
    implements strategies to overcome them.
    Such strategies use parts of the previously presented
    techniques MVCC and transaction-rollback, plus additional
    features.
   </para>

   <bridgehead renderas="sect2">Failures at the client side</bridgehead>
   <para>
    A <glossterm linkend="glossary-client">client</glossterm>
    can fail in different ways. Its hardware can get damaged,
    the power supply can fail, the network connection to the
    server can break, or the client application may run into
    a severe software error like a null pointer exception.
    Because <productname>PostgreSQL</productname> uses a
    client/server architecture, no direct problem for the
    database will occur. In all of these cases, the
    <glossterm linkend="glossary-backend">Backend process</glossterm>,
    which is the client's counterpart at the server side,
    may recognize that the network connection is no longer
    working, or it may run into a timeout after a while. It
    terminates, and there is no harm to the database. As
    usual, uncommitted data changes initiated by this client
    are not visible to any other client.
   </para>

   <bridgehead renderas="sect2">Failures at the server-side</bridgehead>

   <bridgehead renderas="sect3">Instance failure</bridgehead>
   <para>
    The Instance may suddenly fail because of <emphasis>power off</emphasis>
    or other problems. This will affect all running processes, the RAM,
    and possibly the consistency of disk files.
   </para>

   <para>
    After a restart, <productname>PostgreSQL</productname>
    automatically recognizes that the last shutdown of the
    Instance did not happen as expected: files might not be
    closed properly and the <literal>postmaster.pid</literal>
    file unexpectedly exists. <productname>PostgreSQL</productname>
    tries to clean up the situation. This is possible because
    all changes in the database are stored twice. First,
    the WAL files contain them as a chronology of
    <glossterm linkend="glossary-wal-record">WAL records</glossterm>,
    which include the new data values and information about commit
    actions. The WAL records are written first. Only then is
    the data itself written to the heap and index files.
    In contrast to the WAL records, this part may or may
    not have been transferred entirely from Shared Memory
    to the files.
   </para>

   <para>
    The automatic recovery searches within the WAL files for
    the latest
    <glossterm linkend="glossary-checkpoint">checkpoint</glossterm>.
    This checkpoint signals that the database files are in
    a consistent state, especially that all WAL records up to
    this point were successfully stored in heap and index files. Starting
    here, the recovery process copies any remaining WAL records
    to heap and index. The result is that the heap files contain all
    changes recorded to the WAL and reach a consistent state. Changes of committed
    transactions are visible; those of uncommitted transactions
    are also in the files, but - as usual - they are never seen
    by any of the following transactions because uncommitted
    changes are never shown. These recovery actions run
    automatically; it is not necessary that a
    database administrator configure or start anything by
    himself.
   </para>

   <bridgehead renderas="sect3">Disk crash</bridgehead>
   <para>
    If a disk crashes, the course of action described previously
    cannot work: it is likely that the WAL files and/or the
    data and index files are no longer available. The
    database administrator must take special actions to
    prepare for such a situation.
   </para>

   <para>
    They obviously need a backup. How to take such a backup
    and use it as a starting point for a recovery of the
    Cluster is explained in more detail in the next
    <link linkend="tutorial-backup">chapter</link>.
   </para>

   <bridgehead renderas="sect3">Disk full</bridgehead>
   <para>
    It is conceivable that over time the disk gets full,
    and there is no room for additional data. In this case,
    <productname>PostgreSQL</productname> stops accepting
    data-modifying commands or even terminates completely.
    Committed data is neither lost nor corrupted.
   </para>

   <para>
    To recover from such a situation, the administrator should
    remove unused files from this disk. But they should never
    delete files from the
    <glossterm linkend="glossary-data-directory">data directory</glossterm>.
    Nearly all of them are necessary for the consistency
    of the database.
   </para>

   <bridgehead renderas="sect2">High availability</bridgehead>
   <para>
    Database servers can work together to allow a second
    server to quickly take over the workload if the
    primary server fails for whatever reason
    (<link linkend="high-availability">high availability</link>),
    or to allow several computers to serve the same data
    for the purpose of load balancing.
   </para>

  </sect1>

  <sect1 id="tutorial-backup">
   <title>Backup</title>

   <para>
    Taking backups is a basic task of database maintenance.
    <productname>PostgreSQL</productname> supports
    three different strategies; each has its own
    strengths and weaknesses.
    <itemizedlist>
     <listitem>
      <simpara>
       File system level backup
      </simpara>
     </listitem>
     <listitem>
      <simpara>
       Logical backup via <command>pg_dump</command>
      </simpara>
     </listitem>
     <listitem>
      <simpara>
       Continuous archiving based on <command>pg_basebackup</command>
       and WAL files
      </simpara>
     </listitem>
    </itemizedlist>
   </para>

   <bridgehead renderas="sect2">File system level backup</bridgehead>
   <para>
    You can use any appropriate OS tool to create a
    <link linkend="backup-file">copy</link>
    of the Cluster's directory structure and files. In
    case of severe problems such a copy can serve as
    the source of recovery. But in order to get a
    <emphasis>USABLE</emphasis> backup by this method,
    the database server <emphasis>MUST</emphasis> be
    shut down during the complete runtime of the copy
    command!
   </para>

   <para>
    The obvious disadvantage of this method is that there
    is a downtime.
    The other two strategies run during regular operating
    times.
   </para>

   <bridgehead renderas="sect2">Logical backup via pg_dump</bridgehead>
   <para>
    The tool <command>pg_dump</command> is able to take a
    <link linkend="backup-dump">copy</link>
    of the complete Cluster or certain parts of it. It stores
    the copy in the form of SQL commands like <command>CREATE</command>
    and <command>COPY</command>. It runs in
    parallel with other processes, in its own transaction.
   </para>

   <para>
    The output of <command>pg_dump</command> may be used as
    input of <command>psql</command> to restore the data
    (or to copy it to another database).
   </para>

   <para>
    The main advantage over the other two methods is that it
    can pick parts of the Cluster, e.g., a single table or one
    database. The other two methods work only at the level of
    the complete Cluster.
   </para>

   <bridgehead renderas="sect2">Continuous archiving based on pg_basebackup and WAL files</bridgehead>
   <para>
    <link linkend="continuous-archiving">This method</link>
    is the most sophisticated and most complex one. It
    consists of two phases.
   </para>

   <para>
    First, you need to create a so-called
    <firstterm>basebackup</firstterm> with the tool
    <command>pg_basebackup</command>. The result is a
    directory structure plus files which contain a
    consistent copy of the original Cluster.
    <command>pg_basebackup</command> runs in
    parallel with other processes in its own transaction.
   </para>

   <para>
    The second step is recommended but not necessary. All
    changes to the data are stored in WAL files. If you
    continuously save such WAL files, you have the history
    of the Cluster. This history can be applied to a
    basebackup in order to recreate
    any state of the Cluster between the time of
    <command>pg_basebackup</command>'s start time and
    any later point in time. This technique
    is called 'Point-in-Time Recovery (PITR)'.
   </para>

   <para>
    If configured, the
    <glossterm linkend="glossary-wal-archiver">Archiver process</glossterm>
    will automatically copy every single WAL file to a save location.
    <link linkend="backup-archiving-wal">Its configuration</link>
    consists mainly of a string that contains a copy command
    in the operating system's syntax. In order to protect your
    data against a disk crash, the destination location
    of a basebackup as well as of the
    <firstterm>archived WAL files</firstterm> should be on a
    disk which is different from the data disk.
   </para>

   <para>
    If it becomes necessary to restore the Cluster, you have to
    copy the basebackup and the archived WAL files to
    their original directories. The configuration of this
    <link linkend="backup-pitr-recovery">recovery procedure</link>
    contains a string with the reversed copy command: from
    archive location to database location.
   </para>

  </sect1>

<!-- ToDo: replication, index-types, extension mechanism, ...
  <sect1 id="tutorial-replication">
   <title>Replication</title>

   <para>
...
   </para>

  </sect1>
-->

 </chapter>
